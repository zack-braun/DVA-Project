{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV, KFold, RepeatedKFold\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from mlxtend.regressor import StackingRegressor\n",
    "\n",
    "warnings.filterwarnings('ignore') # 'once' shows warning just first time it is triggered\n",
    "# We just use filterwarnings('ignore') to stop warnings from being sown for SKLEARN changes to defaults in upcoming versions\n",
    "\n",
    "# We'll use boston housing data as an example\n",
    "#bh = load_boston()\n",
    "#target = bh.target\n",
    "#x_data = bh.data\n",
    "\n",
    "# We will evaluate the models using mean squared error\n",
    "# Since Python's Sklearn requires scorer to have greater is better property\n",
    "# We'll use the negated mean squared error as our scorer using make_scorer function\n",
    "scorer = make_scorer(mean_squared_error, greater_is_better = False)\n",
    "\n",
    "#Where applicable we'll use the same random seed\n",
    "rand_state = 748932\n",
    "\n",
    "# We'll pass an instance or repeatedstratified Kfold to the GridSearchCV\n",
    "cv_strategy = KFold(n_splits = 10, shuffle = True, random_state = rand_state)\n",
    "#cv_strategy = RepeatedKFold(n_splits=10, n_repeats=3, random_state=rand_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can build a model to predict the DW-Nominate scores for junionr legislators, we must first prepare our dataset. This section reads in the legislator and campaign finance data, join them, and cleans the data for downstream use in a machine learning model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dw_nominate</th>\n",
       "      <th>chamber</th>\n",
       "      <th>gender</th>\n",
       "      <th>missed_votes_pct</th>\n",
       "      <th>party</th>\n",
       "      <th>seniority</th>\n",
       "      <th>state</th>\n",
       "      <th>title</th>\n",
       "      <th>votes_with_party_pct</th>\n",
       "      <th>BirthYear</th>\n",
       "      <th>...</th>\n",
       "      <th>C90017708</th>\n",
       "      <th>C00647701</th>\n",
       "      <th>C00655696</th>\n",
       "      <th>C00473371</th>\n",
       "      <th>C00399865</th>\n",
       "      <th>C00676635</th>\n",
       "      <th>C00545616</th>\n",
       "      <th>C00031054</th>\n",
       "      <th>C00195065</th>\n",
       "      <th>C00679688</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.508</td>\n",
       "      <td>House</td>\n",
       "      <td>M</td>\n",
       "      <td>1.49</td>\n",
       "      <td>R</td>\n",
       "      <td>4</td>\n",
       "      <td>LA</td>\n",
       "      <td>Representative</td>\n",
       "      <td>97.48</td>\n",
       "      <td>1954</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.549</td>\n",
       "      <td>House</td>\n",
       "      <td>M</td>\n",
       "      <td>1.01</td>\n",
       "      <td>R</td>\n",
       "      <td>2</td>\n",
       "      <td>KS</td>\n",
       "      <td>Representative</td>\n",
       "      <td>98.26</td>\n",
       "      <td>1956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>0.425</td>\n",
       "      <td>House</td>\n",
       "      <td>M</td>\n",
       "      <td>6.68</td>\n",
       "      <td>R</td>\n",
       "      <td>32</td>\n",
       "      <td>TX</td>\n",
       "      <td>Representative</td>\n",
       "      <td>98.76</td>\n",
       "      <td>1947</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.648</td>\n",
       "      <td>House</td>\n",
       "      <td>M</td>\n",
       "      <td>0.08</td>\n",
       "      <td>R</td>\n",
       "      <td>8</td>\n",
       "      <td>MI</td>\n",
       "      <td>Representative</td>\n",
       "      <td>66.09</td>\n",
       "      <td>1980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>-0.449</td>\n",
       "      <td>House</td>\n",
       "      <td>M</td>\n",
       "      <td>7.84</td>\n",
       "      <td>D</td>\n",
       "      <td>6</td>\n",
       "      <td>CA</td>\n",
       "      <td>Representative</td>\n",
       "      <td>94.60</td>\n",
       "      <td>1941</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 4336 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     dw_nominate chamber gender  missed_votes_pct party  seniority state  \\\n",
       "0          0.508   House      M              1.49     R          4    LA   \n",
       "126        0.549   House      M              1.01     R          2    KS   \n",
       "384        0.425   House      M              6.68     R         32    TX   \n",
       "5          0.648   House      M              0.08     R          8    MI   \n",
       "249       -0.449   House      M              7.84     D          6    CA   \n",
       "\n",
       "              title  votes_with_party_pct BirthYear  ...  C90017708  \\\n",
       "0    Representative                 97.48      1954  ...        0.0   \n",
       "126  Representative                 98.26      1956  ...        0.0   \n",
       "384  Representative                 98.76      1947  ...        0.0   \n",
       "5    Representative                 66.09      1980  ...        0.0   \n",
       "249  Representative                 94.60      1941  ...        0.0   \n",
       "\n",
       "     C00647701  C00655696  C00473371  C00399865  C00676635  C00545616  \\\n",
       "0          0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "126        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "384        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "5          0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "249        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "     C00031054  C00195065  C00679688  \n",
       "0          0.0        0.0        0.0  \n",
       "126        0.0        0.0        0.0  \n",
       "384        0.0        0.0        0.0  \n",
       "5          0.0        0.0        0.0  \n",
       "249        0.0        0.0        0.0  \n",
       "\n",
       "[5 rows x 4336 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The combined data has 547 rows and 4336 columns\n"
     ]
    }
   ],
   "source": [
    "# This reads the user data from Github\n",
    "donationDataLocation = \"https://raw.githubusercontent.com/zack-braun/DVA-Project/master/experiments/Donations%20to%20Cand%20by%20Committee.csv\"\n",
    "campaignDF = pd.read_csv(donationDataLocation)\n",
    "campaignDF.rename({'Candidate_ID':'opensecrets'} , axis = 1, inplace = True)\n",
    "campaignDF.fillna(0, inplace = True)\n",
    "#display(campaignDF.sample(5))\n",
    "#print('The campaign data has', campaignDF.shape[0], 'rows and', campaignDF.shape[1], 'columns')\n",
    "\n",
    "# This reads in the legislator data\n",
    "legislatorData = \"https://raw.githubusercontent.com/zack-braun/DVA-Project/master/experiments/combinedData.csv\"\n",
    "legislatorDF = pd.read_csv(legislatorData)\n",
    "legislatorDF['BirthYear'] = legislatorDF.date_of_birth.str.split(\"-\", expand = True)[0]\n",
    "dropColz = ['index', 'govtrack_id', 'congress', 'district', 'first_name', 'last_name','last_updated', 'date_of_birth',\n",
    "            'short_title', 'missed_votes', 'middle_name', 'next_election', 'total_votes', 'total_present', 'at_large',\n",
    "            'office', 'in_office', 'Finance', 'suffix', 'leadership_role', 'senate_class', 'state_rank', \n",
    "            'bioguide', 'ideaology']\n",
    "legislatorDF.drop(dropColz , axis = 1, inplace = True)\n",
    "#display(legislatorDF.sample(5))\n",
    "#print('The legislator data has', legislatorDF.shape[0], 'rows and', legislatorDF.shape[1], 'columns')\n",
    "\n",
    "\n",
    "combinedData = pd.merge(legislatorDF, campaignDF, on='opensecrets' , how=\"inner\" )\n",
    "combinedData.drop(['opensecrets'], axis = 1, inplace = True)\n",
    "display(combinedData.sample(5))\n",
    "print('The combined data has', combinedData.shape[0], 'rows and', combinedData.shape[1], 'columns')\n",
    "\n",
    "target = combinedData['dw_nominate']\n",
    "x_data = combinedData.copy()\n",
    "x_data.drop(['dw_nominate'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Prediction Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DW-Nominate scores are continuous over their relevant range. Therefore, we will treat this as a regression problem and use several suitable machine learning approaches. As is common in regression problems, we will use cross-validated mean squared error to judge model performance.\n",
    "\n",
    "Several of the models require that the input data is standardized. For these models we will use sklearn's prediction pipeline capabilities to ensure the standardization occurs as part of our cross-validated model tuning. For the remaining models we will use the un-standardized features in our model.In that case, we will use a different prediction pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = list(x_data._get_numeric_data().columns)\n",
    "categorical_features = list(x_data.columns.difference(numeric_features))\n",
    "\n",
    "# We create seperate Pipelines for these columns\n",
    "numeric_transformer = Pipeline(steps = [('scaler', StandardScaler())])\n",
    "categorical_transformer = Pipeline(steps = [('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer( transformers = [('num', numeric_transformer, numeric_features),\n",
    "                                                 ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# The final step is append the regression model to the prediction pipeline\n",
    "# This will be handled in each section below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Regression (SVR) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Regression provides a alternative to regular regression. Rather than minimizing squared error as in standard OLS style regression, it is looking to minimize the error while allowing the fitted model to be less sensitive to errrors within a margin (typically referred to as epsilon). As discussed in our final report, past research has used SVR to predict DW-Nominate scores as a function of campaign finance data. Those methods involved the use of a large number of features indicating the amount of donations from different donors. We use similar methods to include the donations from different donors in our implementation of SVR, as well as the other models. We augment these features by also including demographic information about the candidate such as the gender, party, and other attributes.\n",
    "\n",
    "Since SVR depends on distance calculations (just like support vector classification), the input features are all standardized during the model cross-validation pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters searched are: {'clf__C': 0.1, 'clf__epsilon': 0.3, 'clf__kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "predPipeSVR = Pipeline(steps = [('preprocessor', preprocessor), ('clf', SVR(gamma = 'scale'))])\n",
    "\n",
    "# We need to tune the parameters c and kernel options:{'linear', 'poly', 'rbf', 'sigmoid'}\n",
    "parameters = {'clf__kernel':('linear', 'rbf', 'poly'), \n",
    "              'clf__C':[0.01, 0.1, 1, 10, 100], \n",
    "              'clf__epsilon':[0.1, 0.3, 0.5, 0.9]}\n",
    "\n",
    "clf = GridSearchCV(predPipeSVR, parameters, scoring = scorer, cv=cv_strategy, n_jobs = -1)\n",
    "clf.fit(x_data, target)\n",
    "\n",
    "resultsSVR = clf.cv_results_\n",
    "\n",
    "print('The best parameters searched are:', clf.best_params_)\n",
    "# The best parameters searched are: {'clf__C': 0.1, 'clf__epsilon': 0.3, 'clf__kernel': 'linear'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Net Regresssion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elastic Net regression uses a weighted average of the Lasso (L1) and Ridge (L2) penalties for regularization as shown in the formula below. \n",
    "\n",
    "$$\\hat{\\beta} = argmin\\left( \\left(y-X\\beta\\right)^2 + \\lambda*\\left(\\alpha*\\sum{\\left|\\beta\\right|} + \\left(1-\\alpha\\right)*\\sum{\\beta^2} \\right) \\right)$$\n",
    "\n",
    "Both penalties trade bias in the coefficient estimates, which are shrunk toward zero, for reduced model variance, which can improve predictive accuracy. \n",
    "\n",
    "When $\\alpha=1$ the penalty reduces to the usual Lasso (L1) penalty in terms of the absolute value of the coefficients. This has the effect that some coefficients are zeroed out or removed from the model, resulting in implicit feature selection. On the other hand $\\alpha=0$ results in the Ridge (L2) penalty. Since the L2 penalty is a function of the squared coefficients, the individual coefficients are shrunk toward zero but not typically zeroed out. \n",
    "\n",
    "The code below tunes the optimal values for alpha (which sklearn call l1_ratio) and lambda (which sklearn confusingly calls alpha).\n",
    "\n",
    "Since the penalties are a function of the coefficients and these in turn are affected by the scale of the data, each regressor is standardized prior to its inclusion in the model as was the case for the SVR model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters searched are: {'clf__alpha': 0.1, 'clf__l1_ratio': 1}\n"
     ]
    }
   ],
   "source": [
    "predPipeENET = Pipeline(steps = [('preprocessor', preprocessor), ('clf', ElasticNet(max_iter = 1500, \n",
    "                                                                                 random_state = rand_state))])\n",
    "\n",
    "# Note: that sklearn's alpha penalty is the same as lambda in R's glmnet package\n",
    "# thus, alpha controls strength of regularization\n",
    "# Note: sklearn's l1_ratio is same as alpha in glmnet and controls mixing of l1 and l2 penalties\n",
    "# l1_ratio = 1 runs straight Lasso, while l1_ratio = 0 runs straight ridge regression\n",
    "\n",
    "parameters = {'clf__alpha':[0.1, 0.5, 1, 3, 5, 10, 100], 'clf__l1_ratio':[0,0.1, 0.25, 0.5, 0.75, 0.9, 1]}\n",
    "clf = GridSearchCV(predPipeENET, parameters, scoring = scorer, cv=cv_strategy, n_jobs = -1)\n",
    "clf.fit(x_data, target)\n",
    "\n",
    "resultsENET = clf.cv_results_\n",
    "\n",
    "print('The best parameters searched are:', clf.best_params_)\n",
    "#The best parameters searched are: {'clf__alpha': 0.1, 'clf__l1_ratio': 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also fit a random forest regressor. This works similar to a random forest classification model, except the mean in each leaf is used for prediction.\n",
    "\n",
    "The code below tunes the maximum number of features to consider for use in making a split, as well as the maximum depth of each tree.\n",
    "\n",
    "Since the random forest model does not use distance in its optimization or penalties that are a function of the coefficients, it is not necessary to standardize the input features prior to fitting the model. However, we choose to apply the same preprocesser function the Random Forest model as was used to scale the other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters searched are: {'clf__max_depth': 30, 'clf__max_features': 500}\n"
     ]
    }
   ],
   "source": [
    "predPipeRF = Pipeline(steps = [('preprocessor', preprocessor), \n",
    "                               ('clf', RandomForestRegressor(n_estimators = 750, random_state = rand_state) )])\n",
    "\n",
    "parameters = {'clf__max_features':[5, 15, 25, 50, 100, 200, 300, 500], 'clf__max_depth':[5, 10, 15, 20, 30, 50, None]}\n",
    "rfclf = GridSearchCV(predPipeRF, parameters, scoring = scorer, cv=cv_strategy, n_jobs = -1)\n",
    "rfclf.fit(x_data, target)\n",
    "\n",
    "resultsRFReg = rfclf.cv_results_\n",
    "\n",
    "print('The best parameters searched are:', rfclf.best_params_)\n",
    "#The best parameters searched are: {'clf__max_depth': 30, 'clf__max_features': 500}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosted Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also try a boosted tree model. Gradient tree boosted regression fits successive regression models to residuals of the previous stage. The prediction function is essentially updated at each iteration as a weighted average of the previous predictive function (combination of trees previous trees) and the current iteration. The weighted combination is controlled by the learning rate. A smaller learning rate indicates that the new tree is given less weight when updating the aggregate prediction. There is a natural trade-off between the learning rate and number of estimators (n_estimators). Smaller learning rates, typically will combine with a larger number of iterations. This analysis uses a learning rate of 0.1 and iteratively fits 200 trees. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.0949           0.0227           19.46s\n",
      "         2           0.0828           0.0129           19.08s\n",
      "         3           0.0629           0.0142           19.20s\n",
      "         4           0.0497           0.0117           19.04s\n",
      "         5           0.0412           0.0090           18.68s\n",
      "         6           0.0330           0.0074           18.76s\n",
      "         7           0.0273           0.0062           18.68s\n",
      "         8           0.0237           0.0035           18.70s\n",
      "         9           0.0188           0.0045           18.63s\n",
      "        10           0.0151           0.0036           18.51s\n",
      "        20           0.0021           0.0004           17.29s\n",
      "        30           0.0003           0.0000           16.16s\n",
      "        40           0.0000           0.0000           14.95s\n",
      "        50           0.0000           0.0000           13.61s\n",
      "        60           0.0000           0.0000           12.13s\n",
      "        70           0.0000           0.0000           10.54s\n",
      "        80           0.0000           0.0000            8.88s\n",
      "        90           0.0000          -0.0000            7.30s\n",
      "       100           0.0000           0.0000            5.99s\n",
      "       200           0.0000          -0.0000            0.00s\n",
      "The best parameters searched are: {'clf__learning_rate': 0.1, 'clf__loss': 'huber', 'clf__max_depth': 50, 'clf__max_features': 'sqrt', 'clf__subsample': 0.75}\n"
     ]
    }
   ],
   "source": [
    "predPipeGBR = Pipeline(steps = [('preprocessor', preprocessor),\n",
    "                                ('clf', GradientBoostingRegressor(n_estimators = 200, random_state = rand_state,\n",
    "                                                                 verbose = 1) )])\n",
    "\n",
    "# We will optimize n_estimators, learning_rate, subsample, max_depth,\n",
    "parameters = {  'clf__loss':['huber'], 'clf__learning_rate':[0.1],\n",
    "                'clf__max_depth':[5, 10, 20, 30, 50], 'clf__subsample':[0.75, 0.85, 0.95],\n",
    "                 'clf__max_features':['sqrt']}\n",
    "\n",
    "clf = GridSearchCV(predPipeGBR, parameters, scoring = scorer, cv=cv_strategy, n_jobs = -1)\n",
    "clf.fit(x_data, target)\n",
    "\n",
    "resultsGBR = clf.cv_results_\n",
    "\n",
    "print('The best parameters searched are:', clf.best_params_)\n",
    "\n",
    "#The best parameters searched are: {'clf__learning_rate': 0.1, 'clf__loss': 'huber', \n",
    "#'clf__max_depth': 50, 'clf__max_features': 'sqrt', 'clf__subsample': 0.75}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After tuning each of the regression models we use the cross-validation results to compare model performance. \n",
    "\n",
    "-  Step 1: Extract RMSE from each cross-validation fold for tuned model\n",
    "-  Step 2: Visualize differences in model performance\n",
    "\n",
    "If we had done repeated cross-validation or used a larger number of folds it would have been possible to perform pairwise T-tests to determine if the best performing model was statistically significantly better than the other models. We leave this excercise for future research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR RMSE: [0.22722715 0.23689728 0.24111844 0.26870878 0.25864968 0.28628547\n",
      " 0.34622652 0.22345364 0.29902676 0.26998553]\n",
      "Elastic Net RMSE: [0.2097773  0.22116155 0.29113264 0.23694606 0.27368186 0.26302499\n",
      " 0.25709182 0.25839708 0.34762817 0.21630336]\n",
      "Random Forest RMSE: [0.09237444 0.09605247 0.1029708  0.10201619 0.1107296  0.11343094\n",
      " 0.0945502  0.08629318 0.08738389 0.11303231]\n",
      "Gradient Boosted Regression Tree RMSE: [0.11573918 0.1060807  0.14908582 0.13139263 0.15899624 0.1356035\n",
      " 0.10396571 0.11506252 0.1098349  0.14594783]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "splitz = ['split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score', \n",
    "          'split5_test_score', 'split6_test_score', 'split7_test_score', 'split8_test_score', 'split9_test_score']\n",
    "\n",
    "rmse = {}\n",
    "# Get RMSE for SVR Model\n",
    "minSVRScoreIdx = np.argmax(resultsSVR['mean_test_score'])\n",
    "rmse['SVR'] = np.array([ np.sqrt(-resultsSVR[split][minSVRScoreIdx]) for split in splitz ])\n",
    "print('SVR RMSE:', rmse['SVR'])\n",
    "\n",
    "# Get RMSE for Elastic Net Model\n",
    "minENETScoreIdx = np.argmax(resultsENET['mean_test_score'])\n",
    "rmse['ENET'] = np.array([ np.sqrt(-resultsENET[split][minENETScoreIdx]) for split in splitz ])\n",
    "print('Elastic Net RMSE:', rmse['ENET'])\n",
    "\n",
    "# Get RMSE for Random Forest Regression Model\n",
    "minRFRegScoreIdx = np.argmax(resultsRFReg['mean_test_score'])\n",
    "rmse['RF'] = np.array([ np.sqrt(-resultsRFReg[split][minRFRegScoreIdx]) for split in splitz ])\n",
    "print('Random Forest RMSE:', rmse['RF'])\n",
    "\n",
    "# Get RMSE for Gradient Boosted Regression Tree\n",
    "minGBRScoreIdx = np.argmax(resultsGBR['mean_test_score'])\n",
    "rmse['GBR'] = np.array([ np.sqrt(-resultsGBR[split][minGBRScoreIdx]) for split in splitz ])\n",
    "print('Gradient Boosted Regression Tree RMSE:', rmse['GBR'])\n",
    "\n",
    "\n",
    "\n",
    "rmse_df = pd.DataFrame(rmse)\n",
    "rmse_df['Fold'] = rmse_df.index + 1\n",
    "rmse_df_long = pd.melt(rmse_df, id_vars = ['Fold'], var_name = 'Model', value_name = 'RMSE')\n",
    "#f, ax = plt.subplots(figsize=(11, 9))\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "ax = sns.boxplot( x = 'Model', y = 'RMSE', data = rmse_df_long)\n",
    "fig = ax.get_figure()\n",
    "fig.savefig(\"C:/Users/rkuhn/Documents/Courses/DataandVisualAnalytics/ProjectpredJuniorLegisDW.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this example code we can conclude that the Elastic Net model had the worst out of sample performance and is probably not the best candidate for use. The Support Vector Regression did slightly better. Past literature had used Support Vector Regression to predict legislator DW-Nominate scores using campaign finance data; however, the Gradient Boosted Regression Tree and Random Forest models both outperformed this model. These are both algorithms that could be useful to other researchers working on this topic in the future. The Random Forest model ultimately had the best average predictive performance and a narrower RMSE variance across the out-of-sample folds.\n",
    "\n",
    "Given its quick time to fit and predictive performance, the Random Forest Regression seems like a good candidate to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1801eb56c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "corr = rmse_df[['ENET', 'RF', 'SVR', 'GBR']].corr()\n",
    "\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "cmap = sns.diverging_palette(240, 10, n=9, as_cmap = True)\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "\n",
    "display(sns.heatmap(corr, cmap=cmap, mask = mask, vmax=1, center=0, square=True, \n",
    "                    linewidths=.5, annot=True, cbar_kws={\"shrink\": .5}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the models are relatively uncorrelated (with the exception of the support vector regression and elastic net), we can probably improve accuracy by averaging our predictions. It has been shown that Elastic Net and Support Vector Regression are related. Since most of the models errors aren't heavily correlated, we choose to try a stacked model to aggregate the predictions and see if it improves the predictive performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked Models: [0.10830503 0.10745868 0.1331932  0.12167784 0.14406623 0.12218015\n",
      " 0.10035428 0.11322675 0.10609487 0.14087484]\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore') # 'once' shows warning just first time it is triggered\n",
    "\n",
    "predPipeRF = Pipeline(steps = [('preprocessor', preprocessor), \n",
    "                                ('clf', RandomForestRegressor(n_estimators= 1000, max_features = 500, \n",
    "                                                              max_depth = 30, random_state = rand_state))])\n",
    "\n",
    "predPipeENET = Pipeline(steps = [('preprocessor', preprocessor), \n",
    "                                 ('clf', ElasticNet(max_iter = 1500, alpha = 0.1, \n",
    "                                                    l1_ratio = 1, random_state = rand_state))])\n",
    "\n",
    "predPipeGBR = Pipeline(steps = [('preprocessor', preprocessor),\n",
    "                                ('clf', GradientBoostingRegressor(n_estimators = 200, random_state = rand_state,\n",
    "                                                                 learning_rate = 0.1, max_features = 'sqrt', \n",
    "                                                                 subsample = 0.75, max_depth = 50, loss = 'huber') )])\n",
    "\n",
    "predPipeSVR = Pipeline(steps = [('preprocessor', preprocessor), \n",
    "                                ('clf', SVR(gamma = 'scale', C = 0.1, epsilon = 0.3, kernel = 'linear'))])\n",
    "\n",
    "rfStack = RandomForestRegressor(n_estimators = 500, random_state = rand_state, max_features = 'auto')\n",
    "\n",
    "regressors = [predPipeRF, predPipeENET, predPipeGBR, predPipeSVR]\n",
    "stregr = StackingRegressor(regressors=regressors, \n",
    "                           meta_regressor=rfStack)\n",
    "\n",
    "parameters = {'meta-randomforestregressor__max_depth':[1, 3, 5, None]}\n",
    "\n",
    "\n",
    "\n",
    "grid = GridSearchCV(estimator=stregr, param_grid=parameters, scoring = scorer, cv=cv_strategy)\n",
    "grid.fit(x_data, target)\n",
    "\n",
    "resultsStack = grid.cv_results_\n",
    "\n",
    "minStackScoreIdx = np.argmax(resultsStack['mean_test_score'])\n",
    "rmse['Stack'] = np.array([ np.sqrt(-resultsStack[split][minStackScoreIdx]) for split in splitz ])\n",
    "print('Stacked Models:', rmse['Stack'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in the chart below, after stacking the models there is a slight improvement in root mean square error relative to the Gradient Boosted Regression Tree model; however, we aren't able to outperform the Random Forest model. Therefore, we elect to use the results of this modeling approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "rmse_df = pd.DataFrame(rmse)\n",
    "rmse_df['Fold'] = rmse_df.index + 1\n",
    "rmse_df_long = pd.melt(rmse_df, id_vars = ['Fold'], var_name = 'Model', value_name = 'RMSE')\n",
    "#f, ax = plt.subplots(figsize=(11, 9))\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "ax = sns.boxplot( x = 'Model', y = 'RMSE', data = rmse_df_long)\n",
    "fig = ax.get_figure()\n",
    "fig.savefig(\"C:/Users/rkuhn/Documents/Courses/DataandVisualAnalytics/Project/predJuniorLegisDWStackedFinal.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chamber</th>\n",
       "      <th>gender</th>\n",
       "      <th>missed_votes_pct</th>\n",
       "      <th>party</th>\n",
       "      <th>seniority</th>\n",
       "      <th>state</th>\n",
       "      <th>title</th>\n",
       "      <th>votes_with_party_pct</th>\n",
       "      <th>BirthYear</th>\n",
       "      <th>C00173393</th>\n",
       "      <th>...</th>\n",
       "      <th>C90017708</th>\n",
       "      <th>C00647701</th>\n",
       "      <th>C00655696</th>\n",
       "      <th>C00473371</th>\n",
       "      <th>C00399865</th>\n",
       "      <th>C00676635</th>\n",
       "      <th>C00545616</th>\n",
       "      <th>C00031054</th>\n",
       "      <th>C00195065</th>\n",
       "      <th>C00679688</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>House</td>\n",
       "      <td>M</td>\n",
       "      <td>0.86</td>\n",
       "      <td>R</td>\n",
       "      <td>2</td>\n",
       "      <td>OH</td>\n",
       "      <td>Representative</td>\n",
       "      <td>100.00</td>\n",
       "      <td>1962</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>House</td>\n",
       "      <td>F</td>\n",
       "      <td>0.00</td>\n",
       "      <td>D</td>\n",
       "      <td>16</td>\n",
       "      <td>GU</td>\n",
       "      <td>Delegate</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1933</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>House</td>\n",
       "      <td>M</td>\n",
       "      <td>0.00</td>\n",
       "      <td>R</td>\n",
       "      <td>2</td>\n",
       "      <td>TX</td>\n",
       "      <td>Representative</td>\n",
       "      <td>95.16</td>\n",
       "      <td>1975</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>House</td>\n",
       "      <td>F</td>\n",
       "      <td>0.00</td>\n",
       "      <td>R</td>\n",
       "      <td>2</td>\n",
       "      <td>PR</td>\n",
       "      <td>Resident Commissioner</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>House</td>\n",
       "      <td>M</td>\n",
       "      <td>0.00</td>\n",
       "      <td>R</td>\n",
       "      <td>2</td>\n",
       "      <td>OK</td>\n",
       "      <td>Representative</td>\n",
       "      <td>97.62</td>\n",
       "      <td>1961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 4335 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  chamber gender  missed_votes_pct party  seniority state  \\\n",
       "0   House      M              0.86     R          2    OH   \n",
       "1   House      F              0.00     D         16    GU   \n",
       "2   House      M              0.00     R          2    TX   \n",
       "3   House      F              0.00     R          2    PR   \n",
       "4   House      M              0.00     R          2    OK   \n",
       "\n",
       "                   title  votes_with_party_pct  BirthYear  C00173393  ...  \\\n",
       "0         Representative                100.00       1962        0.0  ...   \n",
       "1               Delegate                  0.00       1933        0.0  ...   \n",
       "2         Representative                 95.16       1975        0.0  ...   \n",
       "3  Resident Commissioner                  0.00       1976        0.0  ...   \n",
       "4         Representative                 97.62       1961        0.0  ...   \n",
       "\n",
       "   C90017708  C00647701  C00655696  C00473371  C00399865  C00676635  \\\n",
       "0        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "1        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "2        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "3        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "4        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "   C00545616  C00031054  C00195065  C00679688  \n",
       "0        0.0        0.0        0.0        0.0  \n",
       "1        0.0        0.0        0.0        0.0  \n",
       "2        0.0        0.0        0.0        0.0  \n",
       "3        0.0        0.0        0.0        0.0  \n",
       "4        0.0        0.0        0.0        0.0  \n",
       "\n",
       "[5 rows x 4335 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#missingDWNominateFile = \"C:/Users/rkuhn/Documents/Courses/DataandVisualAnalytics/Project/missingDW.csv\"\n",
    "missingDWNominateFile = \"https://raw.githubusercontent.com/zack-braun/DVA-Project/master/experiments/missingDW.csv\"\n",
    "missingDW = pd.read_csv(missingDWNominateFile)\n",
    "missingDW.drop(['Unnamed: 0', 'dw_nominate'], axis = 1, inplace = True )\n",
    "\n",
    "missingDW = pd.merge(missingDW, campaignDF, on='opensecrets' , how=\"left\" )\n",
    "\n",
    "missingDW.drop(['opensecrets', 'govtrack_id'], axis = 1, inplace = True)\n",
    "missingDW = missingDW.fillna(0, axis = 1)\n",
    "display(missingDW.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.43571434, -0.34941749,  0.61175969,  0.47391191,  0.5309464 ,\n",
       "       -0.33869272, -0.438044  , -0.37518259,  0.48750696, -0.37593478,\n",
       "       -0.33284457, -0.31910814,  0.48089045])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We make our predictions with the RF model\n",
    "predictedDW = rfclf.predict(missingDW)\n",
    "\n",
    "\n",
    "\n",
    "display(predictedDW)\n",
    "DWNom = pd.Series(predictedDW)\n",
    "missingDW['dw_nominate'] = DWNom\n",
    "missingDW.to_csv('C:/Users/rkuhn/Documents/Courses/DataandVisualAnalytics/Project/missingDWpredictionsFinal.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
